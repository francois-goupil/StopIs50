{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from scipy.misc     import imsave\n",
    "from keras          import metrics\n",
    "from PIL            import Image\n",
    "\n",
    "from keras import layers\n",
    "from keras.models                      import Model, load_model, Sequential\n",
    "from keras.applications.vgg16          import VGG16\n",
    "from keras.applications.vgg16          import decode_predictions\n",
    "from keras.utils.np_utils              import to_categorical\n",
    "\n",
    "import keras.backend     as K\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_mem():\n",
    "    cfg                          = K.tf.ConfigProto()\n",
    "    cfg.gpu_options.allow_growth = True\n",
    "    K.set_session(K.tf.Session(config = cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_title(category, proba):\n",
    "    return '\"%s\" %.1f%% confidence' % (category.replace('_', ' '), proba * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_title(model, array):\n",
    "    prediction = model.predict(array)\n",
    "    _, category, proba = decode_predictions(prediction)[0][0]\n",
    "    \n",
    "    return create_title(category, proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'images/stop2.jpeg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "The goal of this notebook is to implement the \"fast gradient sign method\" presented in [Explaining and Harnessing Adversarial Examples](https://arxiv.org/abs/1412.6572). This method is used to modify classical samples that a deep neural network trained classification will fail to classify properly.\n",
    "\n",
    "![fgsm idea](http://karpathy.github.io/assets/break/breakconv.png \"Fast Gradient Sign Method\")\n",
    "\n",
    "The idea of this method is to take a sample, ask the network to classify it, compute the gradient of the loss in function of the input pixels and update the picture by a small amount in the direction of the gradient. This direction is opposite to the one that would increase the score for the correct class.\n",
    "\n",
    "# VGG loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 48, 48, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=48x48 at 0x7F13642BB908>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_pic   = Image.open(filename).resize((48, 48))\n",
    "original_array = np.expand_dims(np.array(original_pic), 0)\n",
    "print(original_array.shape)\n",
    "original_pic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform the image according to the VGG16 requirements. It consists in substracting the mean value for each channel and reversing the order of the channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 48, 48, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 46, 46, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 21, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 19, 19, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 5, 5, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 43)                22059     \n",
      "=================================================================\n",
      "Total params: 571,723\n",
      "Trainable params: 571,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "imagenet_mean      = np.array([123.68, 116.779, 103.939], dtype = np.float32)\n",
    "#preprocess         = lambda x: (x - imagenet_mean)[:, :, :, ::-1]\n",
    "#deprocess          = lambda x: (x[:, :, :, ::-1] + imagenet_mean)\n",
    "\n",
    "preprocess         = lambda x: (x - imagenet_mean)\n",
    "deprocess          = lambda x: (x + imagenet_mean)\n",
    "preprocessed_array = preprocess(original_array)\n",
    "#preprocessed_array = preprocessed_array.reshape(1,3,48,48)\n",
    "print(preprocessed_array.shape)\n",
    "model              = load_model('model_pur_transfert_VGG16_roadsigns.h5')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's ask the network what he sees in the picture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "#pred = model.predict(preprocessed_array).argmax()\n",
    "pred = model.predict(original_array).argmax()\n",
    "#print(*[p[1:] for p in decode_predictions(pred)[0]], sep = '\\n')\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial example generation\n",
    "\n",
    "Now we try to confuse the network by modifying the brocoli picture. We first compute the derivatives of the loss function according to the pixels of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable /= will be deprecated. Use `var.assign(var / other)` if you want assignment to the variable value or `x = x / y` if you want a new python Tensor object.\n"
     ]
    }
   ],
   "source": [
    "target_idx      = model.predict(original_array).argmax()\n",
    "target          = to_categorical(target_idx, 43)\n",
    "target_variable = K.variable(target)\n",
    "loss            = metrics.categorical_crossentropy(model.output, target_variable)\n",
    "gradients       = K.gradients(loss, model.input)\n",
    "get_grad_values = K.function([model.input], gradients)\n",
    "grad_values     = get_grad_values([original_array])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the article, we will just use the signs of the derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_signs = np.sign(grad_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we multiply these values by a very small number and add them to the pixel values of the original image. The conversion to uint8 is necessary to get a proper display using imshow ([Stackoverflow](https://stackoverflow.com/questions/39925420/bizzare-matplotlib-behaviour-in-displaying-images-cast-as-floats)). We also clip the values to the interval [0, 255] to get a valid image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon         = 4\n",
    "perturbation    = grad_signs * epsilon\n",
    "#modified_array  = preprocessed_array + perturbation\n",
    "modified_array  = preprocessed_array + perturbation\n",
    "deprocess_array = np.clip(deprocess(modified_array), 0., 255.).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#title_original     = generate_title(model, preprocessed_array)\n",
    "#title_perturbation = generate_title(model, perturbation)\n",
    "#title_modified     = generate_title(model, modified_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (17, 17))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(original_array[0])\n",
    "#plt.title(title_original)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(perturbation[0])\n",
    "#plt.title(title_perturbation)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(deprocess_array[0])\n",
    "#plt.title(title_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean value of perturbation:', perturbation.mean())\n",
    "pred = model.predict(modified_array).argmax()\n",
    "print(pred)\n",
    "#print(*[p[1:] for p in decode_predictions(pred)[0]], sep = '\\n')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
