{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from scipy.misc     import imsave\n",
    "from keras          import metrics\n",
    "from PIL            import Image\n",
    "\n",
    "from keras import layers\n",
    "from keras.models                      import Model, load_model, Sequential\n",
    "from keras.applications.vgg16          import VGG16\n",
    "from keras.applications.vgg16          import decode_predictions\n",
    "from keras.utils.np_utils              import to_categorical\n",
    "\n",
    "import keras.backend     as K\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cleverhans.utils_keras import KerasModelWrapper\n",
    "from cleverhans.attacks import FastGradientMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_mem():\n",
    "    cfg                          = K.tf.ConfigProto()\n",
    "    cfg.gpu_options.allow_growth = True\n",
    "    K.set_session(K.tf.Session(config = cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_title(category, proba):\n",
    "    return '\"%s\" %.1f%% confidence' % (category.replace('_', ' '), proba * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_title(model, array):\n",
    "    prediction = model.predict(array)\n",
    "    _, category, proba = decode_predictions(prediction)[0][0]\n",
    "    \n",
    "    return create_title(category, proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'images/stop2.jpeg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "The goal of this notebook is to implement the \"fast gradient sign method\" presented in [Explaining and Harnessing Adversarial Examples](https://arxiv.org/abs/1412.6572). This method is used to modify classical samples that a deep neural network trained classification will fail to classify properly.\n",
    "\n",
    "![fgsm idea](http://karpathy.github.io/assets/break/breakconv.png \"Fast Gradient Sign Method\")\n",
    "\n",
    "The idea of this method is to take a sample, ask the network to classify it, compute the gradient of the loss in function of the input pixels and update the picture by a small amount in the direction of the gradient. This direction is opposite to the one that would increase the score for the correct class.\n",
    "\n",
    "# VGG loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 48, 48, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=48x48 at 0x7F13642BB908>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_pic   = Image.open(filename).resize((48, 48))\n",
    "original_array = np.expand_dims(np.array(original_pic), 0)\n",
    "print(original_array.shape)\n",
    "original_pic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform the image according to the VGG16 requirements. It consists in substracting the mean value for each channel and reversing the order of the channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 48, 48, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 46, 46, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 21, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 19, 19, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 5, 5, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 43)                22059     \n",
      "=================================================================\n",
      "Total params: 571,723\n",
      "Trainable params: 571,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "imagenet_mean      = np.array([123.68, 116.779, 103.939], dtype = np.float32)\n",
    "#preprocess         = lambda x: (x - imagenet_mean)[:, :, :, ::-1]\n",
    "#deprocess          = lambda x: (x[:, :, :, ::-1] + imagenet_mean)\n",
    "\n",
    "preprocess         = lambda x: (x - imagenet_mean)\n",
    "deprocess          = lambda x: (x + imagenet_mean)\n",
    "preprocessed_array = preprocess(original_array)\n",
    "#preprocessed_array = preprocessed_array.reshape(1,3,48,48)\n",
    "print(preprocessed_array.shape)\n",
    "model              = load_model('model_pur_transfert_VGG16_roadsigns.h5')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's ask the network what he sees in the picture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "#pred = model.predict(preprocessed_array).argmax()\n",
    "pred = model.predict(original_array).argmax()\n",
    "#print(*[p[1:] for p in decode_predictions(pred)[0]], sep = '\\n')\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial example generation\n",
    "\n",
    "Now we try to confuse the network by modifying the brocoli picture. We first compute the derivatives of the loss function according to the pixels of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable /= will be deprecated. Use `var.assign(var / other)` if you want assignment to the variable value or `x = x / y` if you want a new python Tensor object.\n"
     ]
    }
   ],
   "source": [
    "target_idx      = model.predict(original_array).argmax()\n",
    "target          = to_categorical(target_idx, 43)\n",
    "target_variable = K.variable(target)\n",
    "loss            = metrics.categorical_crossentropy(model.output, target_variable)\n",
    "gradients       = K.gradients(loss, model.input)\n",
    "get_grad_values = K.function([model.input], gradients)\n",
    "grad_values     = get_grad_values([original_array])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the article, we will just use the signs of the derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_signs = np.sign(grad_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we multiply these values by a very small number and add them to the pixel values of the original image. The conversion to uint8 is necessary to get a proper display using imshow ([Stackoverflow](https://stackoverflow.com/questions/39925420/bizzare-matplotlib-behaviour-in-displaying-images-cast-as-floats)). We also clip the values to the interval [0, 255] to get a valid image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon         = 4\n",
    "perturbation    = grad_signs * epsilon\n",
    "#modified_array  = preprocessed_array + perturbation\n",
    "modified_array  = preprocessed_array + perturbation\n",
    "deprocess_array = np.clip(deprocess(modified_array), 0., 255.).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer model_1 was called with an input that isn't a symbolic tensor. Received type: <type 'numpy.ndarray'>. Full input: [array([[[[127, 126, 132],\n         [254, 255, 253],\n         [246, 253, 245],\n         ..., \n         [111, 108,  93],\n         [ 94,  96,  59],\n         [ 84,  86,  49]],\n\n        [[255, 255, 255],\n         [253, 255, 252],\n         [116, 121, 117],\n         ..., \n         [210, 214, 200],\n         [118, 115,  84],\n         [ 89,  93,  58]],\n\n        [[247, 249, 246],\n         [249, 251, 250],\n         [ 89,  88,  93],\n         ..., \n         [149, 139, 137],\n         [148, 143, 114],\n         [140, 142, 102]],\n\n        ..., \n        [[ 66,  70,  53],\n         [ 89,  88,  83],\n         [ 53,  44,  47],\n         ..., \n         [154, 142, 144],\n         [ 82,  81,  76],\n         [141, 143, 130]],\n\n        [[ 61,  65,  66],\n         [140, 139, 135],\n         [108, 101,  93],\n         ..., \n         [139, 129, 130],\n         [144, 145, 140],\n         [127, 124, 107]],\n\n        [[148, 136, 146],\n         [101,  92,  93],\n         [114, 111, 106],\n         ..., \n         [122, 113, 114],\n         [110, 110, 102],\n         [ 53,  46,  36]]]], dtype=uint8)]. All inputs to the layer should be tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-583fd2c21b0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mfgsm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastGradientMethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfgsm_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0madv_clever\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfgsm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mpred_adv_clever\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_clever\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goupilfran/anaconda3/envs/tensorflow_env/lib/python2.7/site-packages/cleverhans/attacks/__init__.pyc\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_nb_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_or_guess_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     return fgm(\n",
      "\u001b[0;32m/home/goupilfran/anaconda3/envs/tensorflow_env/lib/python2.7/site-packages/cleverhans/attacks/__init__.pyc\u001b[0m in \u001b[0;36mget_or_guess_labels\u001b[0;34m(self, x, kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m       \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m       \u001b[0mpreds_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m       \u001b[0moriginal_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goupilfran/anaconda3/envs/tensorflow_env/lib/python2.7/site-packages/cleverhans/utils_keras.pyc\u001b[0m in \u001b[0;36mget_probs\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_softmax_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goupilfran/anaconda3/envs/tensorflow_env/lib/python2.7/site-packages/cleverhans/utils_keras.pyc\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, x, layer)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \"\"\"\n\u001b[1;32m    226\u001b[0m     \u001b[0;31m# Return the symbolic representation for this layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m       \u001b[0mrequested\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goupilfran/anaconda3/envs/tensorflow_env/lib/python2.7/site-packages/cleverhans/utils_keras.pyc\u001b[0m in \u001b[0;36mfprop\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;31m# and get the outputs for that model on the input x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;31m# Keras only returns a list for outputs of length >= 1, if the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goupilfran/anaconda3/envs/tensorflow_env/lib/python2.7/site-packages/keras/engine/base_layer.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;31m# with the input_spec set at build time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;31m# Handle mask propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goupilfran/anaconda3/envs/tensorflow_env/lib/python2.7/site-packages/keras/engine/base_layer.pyc\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    283\u001b[0m                                  \u001b[0;34m'Received type: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full input: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. All inputs to the layer '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m                                  'should be tensors.')\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer model_1 was called with an input that isn't a symbolic tensor. Received type: <type 'numpy.ndarray'>. Full input: [array([[[[127, 126, 132],\n         [254, 255, 253],\n         [246, 253, 245],\n         ..., \n         [111, 108,  93],\n         [ 94,  96,  59],\n         [ 84,  86,  49]],\n\n        [[255, 255, 255],\n         [253, 255, 252],\n         [116, 121, 117],\n         ..., \n         [210, 214, 200],\n         [118, 115,  84],\n         [ 89,  93,  58]],\n\n        [[247, 249, 246],\n         [249, 251, 250],\n         [ 89,  88,  93],\n         ..., \n         [149, 139, 137],\n         [148, 143, 114],\n         [140, 142, 102]],\n\n        ..., \n        [[ 66,  70,  53],\n         [ 89,  88,  83],\n         [ 53,  44,  47],\n         ..., \n         [154, 142, 144],\n         [ 82,  81,  76],\n         [141, 143, 130]],\n\n        [[ 61,  65,  66],\n         [140, 139, 135],\n         [108, 101,  93],\n         ..., \n         [139, 129, 130],\n         [144, 145, 140],\n         [127, 124, 107]],\n\n        [[148, 136, 146],\n         [101,  92,  93],\n         [114, 111, 106],\n         ..., \n         [122, 113, 114],\n         [110, 110, 102],\n         [ 53,  46,  36]]]], dtype=uint8)]. All inputs to the layer should be tensors."
     ]
    }
   ],
   "source": [
    "fgsm_params = {\n",
    "      'eps': 0.3,\n",
    "      'y': 14,\n",
    "      'y_target': 10,\n",
    "      'clip_min': 0.,\n",
    "      'clip_max': 1.\n",
    "  }\n",
    "\n",
    "# Initialize the Fast Gradient Sign Method (FGSM) attack object\n",
    "wrap = KerasModelWrapper(model)\n",
    "fgsm = FastGradientMethod(wrap)\n",
    "\n",
    "fgsm = FastGradientMethod(wrap, **fgsm_params)\n",
    "adv_clever = fgsm.generate(original_array)\n",
    "pred_adv_clever = model.predict(adv_clever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#title_original     = generate_title(model, preprocessed_array)\n",
    "#title_perturbation = generate_title(model, perturbation)\n",
    "#title_modified     = generate_title(model, modified_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (17, 17))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(original_array[0])\n",
    "#plt.title(title_original)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(perturbation[0])\n",
    "#plt.title(title_perturbation)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(deprocess_array[0])\n",
    "#plt.title(title_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean value of perturbation:', perturbation.mean())\n",
    "pred = model.predict(modified_array).argmax()\n",
    "print(pred)\n",
    "#print(*[p[1:] for p in decode_predictions(pred)[0]], sep = '\\n')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
